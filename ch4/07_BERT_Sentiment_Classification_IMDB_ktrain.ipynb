{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"07_BERT_Sentiment_Classification_IMDB_ktrain.ipynb","provenance":[{"file_id":"https://github.com/practical-nlp/practical-nlp/blob/master/Ch4/07_BERT_Sentiment_Classification_IMDB_ktrain.ipynb","timestamp":1619204780233}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ypR4NNY7oyEV"},"source":["#### We need to install the ktrain library. Its a light weight wrapper for keras to help train neural networks. With only a few lines of code it allows you to build models, estimate optimal learning rate, loading and preprocessing text and image data from various sources and much more. More about our approach can be found at [this](https://towardsdatascience.com/bert-text-classification-in-3-lines-of-code-using-keras-264db7e7a358) article."]},{"cell_type":"code","metadata":{"id":"58WB13Jx3rQm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635972438441,"user_tz":240,"elapsed":37392,"user":{"displayName":"dung tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3Re1ab2ZEJ5Z3LszcblJMPlArZupaifrPJWH2RXM=s64","userId":"14954118940859551276"}},"outputId":"527778fe-9715-477e-d384-07995cd7c60d"},"source":["!pip3 install ktrain"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ktrain\n","  Downloading ktrain-0.28.2.tar.gz (25.3 MB)\n","\u001b[K     |████████████████████████████████| 25.3 MB 64 kB/s \n","\u001b[?25hCollecting scikit-learn==0.23.2\n","  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n","\u001b[K     |████████████████████████████████| 6.8 MB 928 kB/s \n","\u001b[?25hRequirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.2.2)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.1.5)\n","Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.23.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ktrain) (21.0)\n","Collecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[K     |████████████████████████████████| 981 kB 40.4 MB/s \n","\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.42.1)\n","Collecting cchardet\n","  Downloading cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263 kB)\n","\u001b[K     |████████████████████████████████| 263 kB 45.2 MB/s \n","\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.0.4)\n","Collecting syntok\n","  Downloading syntok-1.3.1.tar.gz (23 kB)\n","Collecting seqeval==0.0.19\n","  Downloading seqeval-0.0.19.tar.gz (30 kB)\n","Collecting transformers<=4.10.3,>=4.0.0\n","  Downloading transformers-4.10.3-py3-none-any.whl (2.8 MB)\n","\u001b[K     |████████████████████████████████| 2.8 MB 19.0 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 24.2 MB/s \n","\u001b[?25hCollecting keras_bert>=0.86.0\n","  Downloading keras-bert-0.88.0.tar.gz (26 kB)\n","Collecting whoosh\n","  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n","\u001b[K     |████████████████████████████████| 468 kB 43.5 MB/s \n","\u001b[?25hCollecting threadpoolctl>=2.0.0\n","  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.19.5)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.4.1)\n","Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.19->ktrain) (2.6.0)\n","Collecting keras-transformer>=0.39.0\n","  Downloading keras-transformer-0.39.0.tar.gz (11 kB)\n","Collecting keras-pos-embd>=0.12.0\n","  Downloading keras-pos-embd-0.12.0.tar.gz (6.0 kB)\n","Collecting keras-multi-head>=0.28.0\n","  Downloading keras-multi-head-0.28.0.tar.gz (14 kB)\n","Collecting keras-layer-normalization>=0.15.0\n","  Downloading keras-layer-normalization-0.15.0.tar.gz (4.2 kB)\n","Collecting keras-position-wise-feed-forward>=0.7.0\n","  Downloading keras-position-wise-feed-forward-0.7.0.tar.gz (4.5 kB)\n","Collecting keras-embed-sim>=0.9.0\n","  Downloading keras-embed-sim-0.9.0.tar.gz (4.1 kB)\n","Collecting keras-self-attention>=0.50.0\n","  Downloading keras-self-attention-0.50.0.tar.gz (12 kB)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0.0->ktrain) (1.15.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 26.3 MB/s \n","\u001b[?25hCollecting huggingface-hub>=0.0.12\n","  Downloading huggingface_hub-0.1.0-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (3.3.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (4.62.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 37.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (4.8.1)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 39.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers<=4.10.3,>=4.0.0->ktrain) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.10.3,>=4.0.0->ktrain) (3.6.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.10.3,>=4.0.0->ktrain) (7.1.2)\n","Building wheels for collected packages: ktrain, seqeval, keras-bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect, syntok\n","  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ktrain: filename=ktrain-0.28.2-py3-none-any.whl size=25290606 sha256=9f7aa9296df2671d09796906b6321e33ba0db88a049e19291eddf0f1e40c5153\n","  Stored in directory: /root/.cache/pip/wheels/df/2b/04/7c821b51e637ec480060989b5030d0c4cce16efe0d67bff94b\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-0.0.19-py3-none-any.whl size=9929 sha256=5c1b5d359ba5d462743fe88ca179c2c435122745dd89819dbae523b53897e32a\n","  Stored in directory: /root/.cache/pip/wheels/f5/ac/f1/4e13d7aff05c722d142b7d20a88ad63f9aab11b895411241a4\n","  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-bert: filename=keras_bert-0.88.0-py3-none-any.whl size=34204 sha256=cbee230283915e6ecd291f95851d926d724a6379a3f8dd66b2a25e51bcf22c62\n","  Stored in directory: /root/.cache/pip/wheels/a2/90/cd/c038f2366929a3a5e3414a303b673e10235e802d871d29a835\n","  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-transformer: filename=keras_transformer-0.39.0-py3-none-any.whl size=12842 sha256=ac2cdf1a6fd97c77ec58f743ac55e2c820a94229e0f41200f5cc5e2b834f9209\n","  Stored in directory: /root/.cache/pip/wheels/bc/01/e0/5a1a14bed6726f2ed73f7917d2d2c2d4081d2c88426dea07ce\n","  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.9.0-py3-none-any.whl size=4504 sha256=fba9f1a920e3944a42e9879a292da9fdd46504b7b4c0fa5604018b6f6192afbe\n","  Stored in directory: /root/.cache/pip/wheels/a8/1e/d2/9bc15513dd2f8b9de3e628b3aa9d2de49e721deef6bbd1497e\n","  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.15.0-py3-none-any.whl size=5224 sha256=2e77a19d5c82ba6515b735d3dfd13ae036a017ffe594007074f551d71eb41c88\n","  Stored in directory: /root/.cache/pip/wheels/4d/be/fe/55422f77ac11fe6ddcb471198038de8a26b5a4dd1557883c1e\n","  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-multi-head: filename=keras_multi_head-0.28.0-py3-none-any.whl size=15559 sha256=d7125d03d2bfcd8a449f7b0f174ab9f32f4e467c5a1dd2b61009c8677256201d\n","  Stored in directory: /root/.cache/pip/wheels/79/4a/ea/9503ab5a02201dfb8635ba2cc8f30844661623c684a5b44472\n","  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.12.0-py3-none-any.whl size=7469 sha256=5843b08659bdf5354ce40aba42b32b83e9faf45a56eaa8dd2fcdcf0f0b785127\n","  Stored in directory: /root/.cache/pip/wheels/77/99/fd/dd98f4876c3ebbef7aab0dbfbd37bca41d7db37d3a28b2cb09\n","  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.7.0-py3-none-any.whl size=5541 sha256=28a0b7d134716a83fd1f4a24200259d4ebd4f764adcbf899e09a8b5969bfbfcf\n","  Stored in directory: /root/.cache/pip/wheels/2d/12/02/1ad455c4f181cda1a4e60c5445855853d5c2ea91f942586a04\n","  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-self-attention: filename=keras_self_attention-0.50.0-py3-none-any.whl size=19414 sha256=e2826218dd86573faa099595de7d465833aa30a7ef368152f1da87af3588ae7b\n","  Stored in directory: /root/.cache/pip/wheels/92/7a/a3/231bef5803298e7ec1815215bc0613239cb1e9c03c57b13c14\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=9455a240b4321182203dba82ba3b1f9e9cbe796dda457f86a64db814dee3ea23\n","  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n","  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for syntok: filename=syntok-1.3.1-py3-none-any.whl size=20917 sha256=aa48873c0395ec715e529535a1701f6c2dfbd834b8aa223f85b0c3cbd7e0e047\n","  Stored in directory: /root/.cache/pip/wheels/5e/c2/33/e5d7d8f2f8b0c391d76bf82b844c3151bf23a84d75d02b185f\n","Successfully built ktrain seqeval keras-bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect syntok\n","Installing collected packages: keras-self-attention, pyyaml, keras-position-wise-feed-forward, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-embed-sim, tokenizers, threadpoolctl, sacremoses, keras-transformer, huggingface-hub, whoosh, transformers, syntok, seqeval, sentencepiece, scikit-learn, langdetect, keras-bert, cchardet, ktrain\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed cchardet-2.1.7 huggingface-hub-0.1.0 keras-bert-0.88.0 keras-embed-sim-0.9.0 keras-layer-normalization-0.15.0 keras-multi-head-0.28.0 keras-pos-embd-0.12.0 keras-position-wise-feed-forward-0.7.0 keras-self-attention-0.50.0 keras-transformer-0.39.0 ktrain-0.28.2 langdetect-1.0.9 pyyaml-6.0 sacremoses-0.0.46 scikit-learn-0.23.2 sentencepiece-0.1.96 seqeval-0.0.19 syntok-1.3.1 threadpoolctl-3.0.0 tokenizers-0.10.3 transformers-4.10.3 whoosh-2.7.4\n"]}]},{"cell_type":"code","metadata":{"id":"KN6N85ah8VXf"},"source":["#Importing\n","import ktrain\n","from ktrain import text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mr1YXudk8Vti","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635972531113,"user_tz":240,"elapsed":40990,"user":{"displayName":"dung tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3Re1ab2ZEJ5Z3LszcblJMPlArZupaifrPJWH2RXM=s64","userId":"14954118940859551276"}},"outputId":"1c0ed38f-2ccc-4965-e9fb-c288f93a0bd8"},"source":["#obtain the dataset\n","import tensorflow as tf\n","dataset = tf.keras.utils.get_file(\n","    fname=\"aclImdb.tar.gz\", \n","    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n","    extract=True,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","84131840/84125825 [==============================] - 7s 0us/step\n","84140032/84125825 [==============================] - 7s 0us/step\n"]}]},{"cell_type":"code","metadata":{"id":"2x46reXu9Kru","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635972531114,"user_tz":240,"elapsed":54,"user":{"displayName":"dung tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3Re1ab2ZEJ5Z3LszcblJMPlArZupaifrPJWH2RXM=s64","userId":"14954118940859551276"}},"outputId":"a17dc30f-8c01-47a5-f092-c8538ce8313e"},"source":["%cd /root/.keras/datasets/aclImdb\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/root/.keras/datasets/aclImdb\n","imdbEr.txt  imdb.vocab\tREADME\ttest  train\n"]}]},{"cell_type":"code","metadata":{"id":"qnXQ-lcL8d6O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635972531116,"user_tz":240,"elapsed":37,"user":{"displayName":"dung tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3Re1ab2ZEJ5Z3LszcblJMPlArZupaifrPJWH2RXM=s64","userId":"14954118940859551276"}},"outputId":"e772e1f4-05dc-4c48-c518-c802afbe2088"},"source":["# set path to dataset\n","import os.path\n","dataset = '/root/.keras/datasets/aclImdb'\n","IMDB_DATADIR = os.path.join(os.path.dirname(dataset), 'aclImdb')\n","print(IMDB_DATADIR)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/root/.keras/datasets/aclImdb\n"]}]},{"cell_type":"markdown","metadata":{"id":"ugopbOABrmne"},"source":["## STEP 1: Preprocessing\n","####The texts_from_folder function will load the training and validation data from the specified folder and automatically preprocess it according to BERT's requirements. In doing so, the BERT model and vocabulary will be automatically downloaded."]},{"cell_type":"code","metadata":{"id":"jELdxonN9J8v","colab":{"base_uri":"https://localhost:8080/","height":298},"executionInfo":{"status":"ok","timestamp":1635972725464,"user_tz":240,"elapsed":194379,"user":{"displayName":"dung tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3Re1ab2ZEJ5Z3LszcblJMPlArZupaifrPJWH2RXM=s64","userId":"14954118940859551276"}},"outputId":"412126c6-7339-48a5-df88-e9d3a2b5b286"},"source":["\n","\n","(x_train, y_train), (x_test, y_test), preproc = text.texts_from_folder(IMDB_DATADIR, \n","                                                                       maxlen=500, \n","                                                                       preprocess_mode='bert',\n","                                                                       train_test_names=['train', \n","                                                                                         'test'],\n","                                                                       classes=['pos', 'neg'])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["detected encoding: utf-8\n","downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n","[██████████████████████████████████████████████████]\n","extracting pretrained BERT model...\n","done.\n","\n","cleanup downloaded zip...\n","done.\n","\n","preprocessing train...\n","language: en\n"]},{"output_type":"display_data","data":{"text/html":["done."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Is Multi-Label? False\n","preprocessing test...\n","language: en\n"]},{"output_type":"display_data","data":{"text/html":["done."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"a0SIaqHcslLZ"},"source":["### STEP 2: Loading a pre trained BERT and wrapping it in a ktrain.learner object"]},{"cell_type":"code","metadata":{"id":"90ftQ6MgAJy4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635972738516,"user_tz":240,"elapsed":13058,"user":{"displayName":"dung tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3Re1ab2ZEJ5Z3LszcblJMPlArZupaifrPJWH2RXM=s64","userId":"14954118940859551276"}},"outputId":"0584159b-4fac-44be-c68d-c604e04bca7d"},"source":["\n","model = text.text_classifier('bert', (x_train, y_train), preproc=preproc)\n","learner = ktrain.get_learner(model,train_data=(x_train, y_train), val_data=(x_test, y_test), batch_size=6)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Is Multi-Label? False\n","maxlen is 500\n","done.\n","CPU times: user 499 ms, sys: 574 ms, total: 1.07 s\n","Wall time: 1.57 s\n"]}]},{"cell_type":"markdown","metadata":{"id":"nN6zWQgys0c_"},"source":["### STEP 3: Training and Tuning the model's parameters"]},{"cell_type":"code","metadata":{"id":"Fxdw88YjAfvF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5a7c41ea-d3fc-4a00-83ef-217df57a0d0d"},"source":["%time learner.fit_onecycle(2e-5, 4)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","begin training using onecycle policy with max lr of 2e-05...\n","Epoch 1/4\n","3706/4167 [=========================>....] - ETA: 11:28 - loss: 0.2633 - accuracy: 0.8892"]}]}]}