{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"04_RecommenderSystems.ipynb","provenance":[{"file_id":"https://github.com/practical-nlp/practical-nlp-code/blob/master/Ch7/04_RecommenderSystems.ipynb","timestamp":1631659434644}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"kJVEnVUtewOb"},"source":["This notebook shows an example recommendation system using doc2vec. We will use a dataset called CMU Book summaries [dataset](http://www.cs.cmu.edu/~dbamman/booksummaries.html). Alternateively, the dataset's link can be found in the `BookSummaries_Link.md` file under the Data folder in Ch7.\n"]},{"cell_type":"code","metadata":{"id":"6mEDv9_hewOc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631659454002,"user_tz":240,"elapsed":8130,"user":{"displayName":"dung tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3Re1ab2ZEJ5Z3LszcblJMPlArZupaifrPJWH2RXM=s64","userId":"14954118940859551276"}},"outputId":"ca04c7e4-6975-44d0-a37e-deffebc19716"},"source":["!pip install gensim\n","!pip install nltk\n","!wget -O booksummaries.tar.gz -q http://www.cs.cmu.edu/~dbamman/data/booksummaries.tar.gz\n","!tar --overwrite -xzf booksummaries.tar.gz"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"]}]},{"cell_type":"code","metadata":{"id":"Se7cRru1ewOd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631660324034,"user_tz":240,"elapsed":809,"user":{"displayName":"dung tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3Re1ab2ZEJ5Z3LszcblJMPlArZupaifrPJWH2RXM=s64","userId":"14954118940859551276"}},"outputId":"111d17d3-5455-4de6-a83c-9f007b13d990"},"source":["from nltk.tokenize import word_tokenize\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","import nltk\n","nltk.download('punkt')\n","import os\n","\n","# Read the dataset’s README to understand the data format.\n","data_path = os.path.join(\"booksummaries\", \"booksummaries.txt\")\n","mydata = {} #titles-summaries dictionary object\n","for line in open(data_path, encoding=\"utf-8\"):\n","    temp = line.split(\"\\t\")\n","    mydata[temp[2]] = temp[6]"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","metadata":{"id":"4CePAAtIewOe"},"source":["#prepare the data for doc2vec, build and save a doc2vec model\n","train_doc2vec = [TaggedDocument((word_tokenize(mydata[t])), tags=[t]) for t in mydata.keys()]\n","model = Doc2Vec(vector_size=50, alpha=0.025, min_count=10, dm =1, epochs=100)\n","model.build_vocab(train_doc2vec)\n","model.train(train_doc2vec, total_examples=model.corpus_count, epochs=model.epochs)\n","model.save(\"d2v.model\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L6JL8uAHewOf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631662281834,"user_tz":240,"elapsed":722,"user":{"displayName":"dung tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3Re1ab2ZEJ5Z3LszcblJMPlArZupaifrPJWH2RXM=s64","userId":"14954118940859551276"}},"outputId":"f439f7bd-a554-442b-c2a9-67a7174de19d"},"source":["%time\n","#Use the model to look for similar texts\n","model= Doc2Vec.load(\"d2v.model\")\n","\n","#This is a sentence from the summary of “Animal Farm” on Wikipedia:\n","#https://en.wikipedia.org/wiki/Animal_Farm\n","sample = \"\"\"\n","Napoleon enacts changes to the governance structure of the farm, replacing meetings with a committee of pigs who will run the farm.\n"," \"\"\"\n","new_vector = model.infer_vector(word_tokenize(sample))\n","sims = model.docvecs.most_similar([new_vector])\n","print(sims)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n","Wall time: 7.15 µs\n","[('Animal Farm', 0.7018142342567444), ('The Wild Irish Girl', 0.6415804624557495), ('Ponni', 0.6028823256492615), (\"Snowball's Chance\", 0.590345561504364), ('Family Matters', 0.5861057043075562), ('The Big Country', 0.5768381357192993), ('The Prophet', 0.5702881217002869), ('Poor White', 0.5645689964294434), (\"Family Guy: Stewie's Guide to World Domination\", 0.5617426633834839), ('The Land of Little Rain', 0.556604266166687)]\n"]}]}]}